{"ast":null,"code":"// import React from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { useHistory } from \"react-router-dom\";\n//\n// import { useSpeechSynthesis } from \"react-speech-kit\";\n//\n// const Assistant = () => {\n//   const history = useHistory();\n//   //   SpeechRecognition.startListening({ continuous: true });\n//   const { speak } = useSpeechSynthesis();\n//   const commands = [\n//     {\n//       command: \"Go to *\",\n//       callback: (link) => {\n//         const x = `Redirect to: ${link}`;\n//         console.log(x);\n//         if (link === \"object detection\") {\n//           speak({ text: x });\n//           history.push(`/object-detection`);\n//         }else if (link === \"face recognition\") {\n//           speak({ text: x });\n//           history.push(`/face-recognition`);\n//         }else if (link === \"image to text\") {\n//           speak({ text: x });\n//           history.push(`/image-to-text`);\n//         } else if (link === \"text to speech\") {\n//           speak({ text: x });\n//           history.push(`/text-to-speech`);\n//         } else if (link === \"speech to text\") {\n//           speak({ text: x });\n//           history.push(`/speech-to-text`);\n//         } else if (link === \"home\") {\n//           speak({ text: x });\n//           history.push(`/`);\n//         } else {\n//           speak({ text: \"I don't get it, Please try again!\" });\n//         }\n//       },\n//     },\n//     {\n//       command: \"Hey Jarvis\",\n//       callback: () => {\n//         speak({ text: \"Hi Sir\" });\n//\n//         console.log(\"hii\");\n//       },\n//       //   matchInterim: true,\n//     },\n//     // {\n//     //   command: \"*\",\n//     //   callback: () => {\n//     //     speak({ text: \"Please repeat\" });\n//\n//     //     console.log(\"repeat\");\n//     //   },\n//     // },\n//   ];\n//   const { transcript: t1 } = useSpeechRecognition({ commands });\n//\n//   return (\n//     <React.Fragment>\n//       <div\n//         className=\"row m-2 p-4\"\n//         style={{ background: \"#f5f5f5\", textAlign: \"center\" }}\n//       >\n//         <h1\n//           style={{\n//             fontFamily: \"Georgia, Times, serif\",\n//             fontSize: \"45px\",\n//             fontWeight: \"bolder\",\n//           }}\n//         >\n//           Assistant\n//         </h1>\n//       </div>\n//       <div style={{ border: \"10px solid gray\", padding: \"10px\" }}>\n// {/*         <div>Say \"Hey Jarvis\"</div> */}\n//         <h3>Say \"Hey Jarvis\"</h3>\n//         <p>{t1 ? t1 : \"Start listening for transcript\"}</p>\n//         <button onClick={SpeechRecognition.startListening}>\n//           Start listening\n//         </button>\n//         &nbsp;\n//         <button onClick={SpeechRecognition.stopListening}>\n//           Stop listening\n//         </button>\n//       </div>\n//     </React.Fragment>\n//   );\n// };\n//\n// export default Assistant;\n\n//////////////////////////////\n\n// import React, { useState } from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { useHistory } from \"react-router-dom\";\n//\n// import { useSpeechSynthesis } from \"react-speech-kit\";\n//\n// const Assistant = () => {\n//   const history = useHistory();\n//   const { speak } = useSpeechSynthesis();\n//   const [isListening, setIsListening] = useState(false);\n//\n//   const startListening = () => {\n//     setIsListening(true);\n//     SpeechRecognition.startListening({ continuous: true });\n//   };\n//\n//   const stopListening = () => {\n//     setIsListening(false);\n//     SpeechRecognition.stopListening();\n//   };\n//\n//   const commands = [\n//     {\n//       command: \"Go to *\",\n//       callback: (link) => {\n//         const x = `Redirect to: ${link}`;\n//         console.log(x);\n//         if (link === \"object detection\") {\n//           speak({ text: x });\n//           history.push(`/object-detection`);\n//         } else if (link === \"face recognition\") {\n//           speak({ text: x });\n//           history.push(`/face-recognition`);\n//         } else if (link === \"image to text\") {\n//           speak({ text: x });\n//           history.push(`/image-to-text`);\n//         } else if (link === \"text to speech\") {\n//           speak({ text: x });\n//           history.push(`/text-to-speech`);\n//         } else if (link === \"speech to text\") {\n//           speak({ text: x });\n//           history.push(`/speech-to-text`);\n//         } else if (link === \"home\") {\n//           speak({ text: x });\n//           history.push(`/`);\n//         } else {\n//           speak({ text: \"I don't get it, Please try again!\" });\n//         }\n//       },\n//     },\n//     {\n//       command: \"Hey Jarvis\",\n//       callback: () => {\n//         speak({ text: \"Hi Sir\" });\n//         console.log(\"hii\");\n//       },\n//     },\n//   ];\n//   const { transcript: t1 } = useSpeechRecognition({ commands });\n//\n//   return (\n//     <div className=\"phone-container\">\n//       <div className=\"phone\">\n//         <div className=\"phone-speaker\"></div>\n//         <div className=\"phone-screen\">\n//           <div className=\"assistant-container\">\n//             <div className=\"assistant-content\">\n//               <div className=\"assistant-title\">\n//                 <h1>Assistant</h1>\n//               </div>\n//               <div className=\"assistant-body\">\n//                 <h3>Say \"Hey Jarvis\"</h3>\n//                 <p>{t1 ? t1 : \"Start listening for transcript\"}</p>\n//                 <button\n//                   onClick={isListening ? stopListening : startListening}\n//                   className={`listening-btn ${isListening ? \"listening\" : \"\"}`}\n//                 >\n//                   {isListening ? \"Listening\" : \"Start Listening\"}\n//                 </button>\n//               </div>\n//             </div>\n//           </div>\n//         </div>\n//         <div className=\"phone-btns\">\n//           <div className=\"phone-btn phone-btn-red\"></div>\n//           <div className=\"phone-btn phone-btn-green\"></div>\n//           <div className=\"phone-btn phone-btn-blue\"></div>\n//         </div>\n//       </div>\n//       <style jsx>{`\n//         .phone-container {\n//           display: flex;\n//           justify-content: center;\n//           align-items: center;\n//           height: 100vh;\n//           background: linear-gradient(135deg, #2d75ff, #a8bfff);\n//         }\n//         .phone {\n//           position: relative;\n//           width: 300px;\n//           height: 600px;\n//           background: #000;\n//           border-radius: 20px;\n//           overflow: hidden;\n//           box-shadow: 0 0 20px rgba(0, 0, 0, 0.5);\n//         }\n//         .phone-speaker {\n//           position: absolute;\n//           top: 20px;\n//           left: 50%;\n//           transform: translateX(-50%);\n//           width: 50px;\n//           height: 5px;\n//           background: #666;\n//           border-radius: 50px;\n//         }\n//         .phone-screen {\n//           position: relative;\n//           width: 100%;\n//           height: 100%; /* Adjusted height */\n//           background: #fff;\n//           overflow-y: auto;\n//           padding: 20px;\n//         }\n//         .assistant-container {\n//           display: flex;\n//           justify-content: center;\n//           align-items: center;\n//           height: 100%;\n//         }\n//         .assistant-content {\n//           text-align: center;\n//         }\n//         .assistant-title {\n//           font-family: Georgia, Times, serif;\n//           font-size: 32px;\n//           font-weight: bolder;\n//           margin-bottom: 20px;\n//         }\n//         .assistant-body {\n//           margin-top: 20px;\n//         }\n//         .listening-btn {\n//           background-color: #f00;\n//           color: #fff;\n//           border: none;\n//           border-radius: 5px;\n//           padding: 10px;\n//           cursor: pointer;\n//           transition: background-color 0.3s ease;\n//         }\n//         .listening-btn.listening {\n//           background-color: #00f;\n//         }\n//         .phone-btns {\n//           position: absolute;\n//           bottom: 10px;\n//           left: 50%;\n//           transform: translateX(-50%);\n//           display: flex;\n//         }\n//         .phone-btn {\n//           width: 20px;\n//           height: 20px;\n//           border-radius: 50%;\n//           margin: 0 5px;\n//         }\n//         .phone-btn-red {\n//           background: #f00;\n//         }\n//         .phone-btn-green {\n//           background: #0f0;\n//         }\n//         .phone-btn-blue {\n//           background: #00f;\n//         }\n//       `}</style>\n//     </div>\n//   );\n// };\n//\n// export default Assistant;\n\n////////////////////////////////////// final working code \n\n// import React, { useState } from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { useHistory } from \"react-router-dom\";\n// import { useSpeechSynthesis } from \"react-speech-kit\";\n//\n// const Assistant = () => {\n//   const history = useHistory();\n//   const { speak } = useSpeechSynthesis();\n//   const [isListening, setIsListening] = useState(false);\n//\n//   const startListening = () => {\n//     setIsListening(true);\n//     SpeechRecognition.startListening({ continuous: true });\n//   };\n//\n//   const stopListening = () => {\n//     setIsListening(false);\n//     SpeechRecognition.stopListening();\n//   };\n//\n//   const commands = [\n//     {\n//       command: \"Go to *\",\n//       callback: (link) => {\n//         const x = `Redirect to: ${link}`;\n//         console.log(x);\n//         if (link === \"object detection\") {\n//           speak({ text: x });\n//           history.push(`/object-detection`);\n//         } else if (link === \"face recognition\") {\n//           speak({ text: x });\n//           history.push(`/face-recognition`);\n//         } else if (link === \"image to text\") {\n//           speak({ text: x });\n//           history.push(`/image-to-text`);\n//         } else if (link === \"text to speech\") {\n//           speak({ text: x });\n//           history.push(`/text-to-speech`);\n//         } else if (link === \"speech to text\") {\n//           speak({ text: x });\n//           history.push(`/speech-to-text`);\n//         } else if (link === \"home\") {\n//           speak({ text: x });\n//           history.push(`/`);\n//         } else {\n//           speak({ text: \"I don't get it, Please try again!\" });\n//         }\n//       },\n//     },\n//     {\n//       command: \"Jarvis\",\n//       callback: () => {\n//         speak({ text: \"Hi Sir\" });\n//         console.log(\"hii\");\n//       },\n//     },\n//   ];\n//   const { transcript: t1 } = useSpeechRecognition({ commands });\n//\n//   return (\n//     <div className=\"phone-container\">\n//       <div className=\"phone\">\n//         <div className=\"phone-screen\">\n//           <div className=\"assistant-container\">\n//             <div className=\"assistant-content\">\n//               <div className=\"assistant-title\">\n//                 <h1>Assistant</h1>\n//               </div>\n//               <div className=\"assistant-body\">\n//                 <h3>Say \"Jarvis\"</h3>\n//                 <p>{t1 ? t1 : \"Start listening for transcript\"}</p>\n//                 <button\n//                   onClick={isListening ? stopListening : startListening}\n//                   className={`listening-btn ${isListening ? \"listening\" : \"\"}`}\n//                 >\n//                   {isListening ? \"Listening\" : \"Start Listening\"}\n//                 </button>\n//               </div>\n//             </div>\n//           </div>\n//         </div>\n//       </div>\n//       <style jsx>{`\n//         .phone-container {\n//           display: flex;\n//           justify-content: center;\n//           align-items: center;\n//           height: 100vh; /* Adjust the height to match FaceRecognition */\n//           background: linear-gradient(135deg, #2d75ff, #a8bfff);\n//           overflow: hidden;\n//         }\n//         .phone {\n//           width: 85%; /* Adjust the width to match FaceRecognition */\n//           height: 95%; /* Adjust the height to match FaceRecognition */\n//           max-width: 750px;\n//           max-height: 800px;\n//           background: #333;\n//           border-radius: 20px;\n//           overflow: hidden;\n//           box-shadow: 0 0 20px rgba(0, 0, 0, 0.5);\n//         }\n//         .phone-screen {\n//           height: 100%;\n//           overflow-y: auto;\n//           padding: 20px;\n//           display: flex;\n//           flex-direction: column;\n//           justify-content: center;\n//           align-items: center;\n//           background: #fff;\n//         }\n//         .assistant-container {\n//           width: 100%;\n//           max-width: 400px;\n//         }\n//         .assistant-content {\n//           text-align: center;\n//         }\n//         .assistant-title {\n//           font-size: 28px;\n//           margin-bottom: 20px;\n//           text-shadow: 1px 1px 2px #000;\n//         }\n//         .assistant-body {\n//           margin-top: 20px;\n//         }\n//         .listening-btn {\n//           background-color: #f00;\n//           color: #fff;\n//           border: none;\n//           border-radius: 5px;\n//           padding: 10px;\n//           cursor: pointer;\n//           transition: background-color 0.3s ease;\n//         }\n//         .listening-btn.listening {\n//           background-color: #00f;\n//         }\n//       `}</style>\n//     </div>\n//   );\n// };\n//\n// export default Assistant;\n\n///////////////////////////////////////////////////","map":{"version":3,"names":[],"sources":["D:/PROJECTS/ScanVue/client/src/components/assistant.jsx"],"sourcesContent":["// import React from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { useHistory } from \"react-router-dom\";\n//\n// import { useSpeechSynthesis } from \"react-speech-kit\";\n//\n// const Assistant = () => {\n//   const history = useHistory();\n//   //   SpeechRecognition.startListening({ continuous: true });\n//   const { speak } = useSpeechSynthesis();\n//   const commands = [\n//     {\n//       command: \"Go to *\",\n//       callback: (link) => {\n//         const x = `Redirect to: ${link}`;\n//         console.log(x);\n//         if (link === \"object detection\") {\n//           speak({ text: x });\n//           history.push(`/object-detection`);\n//         }else if (link === \"face recognition\") {\n//           speak({ text: x });\n//           history.push(`/face-recognition`);\n//         }else if (link === \"image to text\") {\n//           speak({ text: x });\n//           history.push(`/image-to-text`);\n//         } else if (link === \"text to speech\") {\n//           speak({ text: x });\n//           history.push(`/text-to-speech`);\n//         } else if (link === \"speech to text\") {\n//           speak({ text: x });\n//           history.push(`/speech-to-text`);\n//         } else if (link === \"home\") {\n//           speak({ text: x });\n//           history.push(`/`);\n//         } else {\n//           speak({ text: \"I don't get it, Please try again!\" });\n//         }\n//       },\n//     },\n//     {\n//       command: \"Hey Jarvis\",\n//       callback: () => {\n//         speak({ text: \"Hi Sir\" });\n//\n//         console.log(\"hii\");\n//       },\n//       //   matchInterim: true,\n//     },\n//     // {\n//     //   command: \"*\",\n//     //   callback: () => {\n//     //     speak({ text: \"Please repeat\" });\n//\n//     //     console.log(\"repeat\");\n//     //   },\n//     // },\n//   ];\n//   const { transcript: t1 } = useSpeechRecognition({ commands });\n//\n//   return (\n//     <React.Fragment>\n//       <div\n//         className=\"row m-2 p-4\"\n//         style={{ background: \"#f5f5f5\", textAlign: \"center\" }}\n//       >\n//         <h1\n//           style={{\n//             fontFamily: \"Georgia, Times, serif\",\n//             fontSize: \"45px\",\n//             fontWeight: \"bolder\",\n//           }}\n//         >\n//           Assistant\n//         </h1>\n//       </div>\n//       <div style={{ border: \"10px solid gray\", padding: \"10px\" }}>\n// {/*         <div>Say \"Hey Jarvis\"</div> */}\n//         <h3>Say \"Hey Jarvis\"</h3>\n//         <p>{t1 ? t1 : \"Start listening for transcript\"}</p>\n//         <button onClick={SpeechRecognition.startListening}>\n//           Start listening\n//         </button>\n//         &nbsp;\n//         <button onClick={SpeechRecognition.stopListening}>\n//           Stop listening\n//         </button>\n//       </div>\n//     </React.Fragment>\n//   );\n// };\n//\n// export default Assistant;\n\n\n\n\n\n\n\n//////////////////////////////\n\n\n\n// import React, { useState } from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { useHistory } from \"react-router-dom\";\n//\n// import { useSpeechSynthesis } from \"react-speech-kit\";\n//\n// const Assistant = () => {\n//   const history = useHistory();\n//   const { speak } = useSpeechSynthesis();\n//   const [isListening, setIsListening] = useState(false);\n//\n//   const startListening = () => {\n//     setIsListening(true);\n//     SpeechRecognition.startListening({ continuous: true });\n//   };\n//\n//   const stopListening = () => {\n//     setIsListening(false);\n//     SpeechRecognition.stopListening();\n//   };\n//\n//   const commands = [\n//     {\n//       command: \"Go to *\",\n//       callback: (link) => {\n//         const x = `Redirect to: ${link}`;\n//         console.log(x);\n//         if (link === \"object detection\") {\n//           speak({ text: x });\n//           history.push(`/object-detection`);\n//         } else if (link === \"face recognition\") {\n//           speak({ text: x });\n//           history.push(`/face-recognition`);\n//         } else if (link === \"image to text\") {\n//           speak({ text: x });\n//           history.push(`/image-to-text`);\n//         } else if (link === \"text to speech\") {\n//           speak({ text: x });\n//           history.push(`/text-to-speech`);\n//         } else if (link === \"speech to text\") {\n//           speak({ text: x });\n//           history.push(`/speech-to-text`);\n//         } else if (link === \"home\") {\n//           speak({ text: x });\n//           history.push(`/`);\n//         } else {\n//           speak({ text: \"I don't get it, Please try again!\" });\n//         }\n//       },\n//     },\n//     {\n//       command: \"Hey Jarvis\",\n//       callback: () => {\n//         speak({ text: \"Hi Sir\" });\n//         console.log(\"hii\");\n//       },\n//     },\n//   ];\n//   const { transcript: t1 } = useSpeechRecognition({ commands });\n//\n//   return (\n//     <div className=\"phone-container\">\n//       <div className=\"phone\">\n//         <div className=\"phone-speaker\"></div>\n//         <div className=\"phone-screen\">\n//           <div className=\"assistant-container\">\n//             <div className=\"assistant-content\">\n//               <div className=\"assistant-title\">\n//                 <h1>Assistant</h1>\n//               </div>\n//               <div className=\"assistant-body\">\n//                 <h3>Say \"Hey Jarvis\"</h3>\n//                 <p>{t1 ? t1 : \"Start listening for transcript\"}</p>\n//                 <button\n//                   onClick={isListening ? stopListening : startListening}\n//                   className={`listening-btn ${isListening ? \"listening\" : \"\"}`}\n//                 >\n//                   {isListening ? \"Listening\" : \"Start Listening\"}\n//                 </button>\n//               </div>\n//             </div>\n//           </div>\n//         </div>\n//         <div className=\"phone-btns\">\n//           <div className=\"phone-btn phone-btn-red\"></div>\n//           <div className=\"phone-btn phone-btn-green\"></div>\n//           <div className=\"phone-btn phone-btn-blue\"></div>\n//         </div>\n//       </div>\n//       <style jsx>{`\n//         .phone-container {\n//           display: flex;\n//           justify-content: center;\n//           align-items: center;\n//           height: 100vh;\n//           background: linear-gradient(135deg, #2d75ff, #a8bfff);\n//         }\n//         .phone {\n//           position: relative;\n//           width: 300px;\n//           height: 600px;\n//           background: #000;\n//           border-radius: 20px;\n//           overflow: hidden;\n//           box-shadow: 0 0 20px rgba(0, 0, 0, 0.5);\n//         }\n//         .phone-speaker {\n//           position: absolute;\n//           top: 20px;\n//           left: 50%;\n//           transform: translateX(-50%);\n//           width: 50px;\n//           height: 5px;\n//           background: #666;\n//           border-radius: 50px;\n//         }\n//         .phone-screen {\n//           position: relative;\n//           width: 100%;\n//           height: 100%; /* Adjusted height */\n//           background: #fff;\n//           overflow-y: auto;\n//           padding: 20px;\n//         }\n//         .assistant-container {\n//           display: flex;\n//           justify-content: center;\n//           align-items: center;\n//           height: 100%;\n//         }\n//         .assistant-content {\n//           text-align: center;\n//         }\n//         .assistant-title {\n//           font-family: Georgia, Times, serif;\n//           font-size: 32px;\n//           font-weight: bolder;\n//           margin-bottom: 20px;\n//         }\n//         .assistant-body {\n//           margin-top: 20px;\n//         }\n//         .listening-btn {\n//           background-color: #f00;\n//           color: #fff;\n//           border: none;\n//           border-radius: 5px;\n//           padding: 10px;\n//           cursor: pointer;\n//           transition: background-color 0.3s ease;\n//         }\n//         .listening-btn.listening {\n//           background-color: #00f;\n//         }\n//         .phone-btns {\n//           position: absolute;\n//           bottom: 10px;\n//           left: 50%;\n//           transform: translateX(-50%);\n//           display: flex;\n//         }\n//         .phone-btn {\n//           width: 20px;\n//           height: 20px;\n//           border-radius: 50%;\n//           margin: 0 5px;\n//         }\n//         .phone-btn-red {\n//           background: #f00;\n//         }\n//         .phone-btn-green {\n//           background: #0f0;\n//         }\n//         .phone-btn-blue {\n//           background: #00f;\n//         }\n//       `}</style>\n//     </div>\n//   );\n// };\n//\n// export default Assistant;\n\n\n\n////////////////////////////////////// final working code \n\n\n\n\n// import React, { useState } from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { useHistory } from \"react-router-dom\";\n// import { useSpeechSynthesis } from \"react-speech-kit\";\n//\n// const Assistant = () => {\n//   const history = useHistory();\n//   const { speak } = useSpeechSynthesis();\n//   const [isListening, setIsListening] = useState(false);\n//\n//   const startListening = () => {\n//     setIsListening(true);\n//     SpeechRecognition.startListening({ continuous: true });\n//   };\n//\n//   const stopListening = () => {\n//     setIsListening(false);\n//     SpeechRecognition.stopListening();\n//   };\n//\n//   const commands = [\n//     {\n//       command: \"Go to *\",\n//       callback: (link) => {\n//         const x = `Redirect to: ${link}`;\n//         console.log(x);\n//         if (link === \"object detection\") {\n//           speak({ text: x });\n//           history.push(`/object-detection`);\n//         } else if (link === \"face recognition\") {\n//           speak({ text: x });\n//           history.push(`/face-recognition`);\n//         } else if (link === \"image to text\") {\n//           speak({ text: x });\n//           history.push(`/image-to-text`);\n//         } else if (link === \"text to speech\") {\n//           speak({ text: x });\n//           history.push(`/text-to-speech`);\n//         } else if (link === \"speech to text\") {\n//           speak({ text: x });\n//           history.push(`/speech-to-text`);\n//         } else if (link === \"home\") {\n//           speak({ text: x });\n//           history.push(`/`);\n//         } else {\n//           speak({ text: \"I don't get it, Please try again!\" });\n//         }\n//       },\n//     },\n//     {\n//       command: \"Jarvis\",\n//       callback: () => {\n//         speak({ text: \"Hi Sir\" });\n//         console.log(\"hii\");\n//       },\n//     },\n//   ];\n//   const { transcript: t1 } = useSpeechRecognition({ commands });\n//\n//   return (\n//     <div className=\"phone-container\">\n//       <div className=\"phone\">\n//         <div className=\"phone-screen\">\n//           <div className=\"assistant-container\">\n//             <div className=\"assistant-content\">\n//               <div className=\"assistant-title\">\n//                 <h1>Assistant</h1>\n//               </div>\n//               <div className=\"assistant-body\">\n//                 <h3>Say \"Jarvis\"</h3>\n//                 <p>{t1 ? t1 : \"Start listening for transcript\"}</p>\n//                 <button\n//                   onClick={isListening ? stopListening : startListening}\n//                   className={`listening-btn ${isListening ? \"listening\" : \"\"}`}\n//                 >\n//                   {isListening ? \"Listening\" : \"Start Listening\"}\n//                 </button>\n//               </div>\n//             </div>\n//           </div>\n//         </div>\n//       </div>\n//       <style jsx>{`\n//         .phone-container {\n//           display: flex;\n//           justify-content: center;\n//           align-items: center;\n//           height: 100vh; /* Adjust the height to match FaceRecognition */\n//           background: linear-gradient(135deg, #2d75ff, #a8bfff);\n//           overflow: hidden;\n//         }\n//         .phone {\n//           width: 85%; /* Adjust the width to match FaceRecognition */\n//           height: 95%; /* Adjust the height to match FaceRecognition */\n//           max-width: 750px;\n//           max-height: 800px;\n//           background: #333;\n//           border-radius: 20px;\n//           overflow: hidden;\n//           box-shadow: 0 0 20px rgba(0, 0, 0, 0.5);\n//         }\n//         .phone-screen {\n//           height: 100%;\n//           overflow-y: auto;\n//           padding: 20px;\n//           display: flex;\n//           flex-direction: column;\n//           justify-content: center;\n//           align-items: center;\n//           background: #fff;\n//         }\n//         .assistant-container {\n//           width: 100%;\n//           max-width: 400px;\n//         }\n//         .assistant-content {\n//           text-align: center;\n//         }\n//         .assistant-title {\n//           font-size: 28px;\n//           margin-bottom: 20px;\n//           text-shadow: 1px 1px 2px #000;\n//         }\n//         .assistant-body {\n//           margin-top: 20px;\n//         }\n//         .listening-btn {\n//           background-color: #f00;\n//           color: #fff;\n//           border: none;\n//           border-radius: 5px;\n//           padding: 10px;\n//           cursor: pointer;\n//           transition: background-color 0.3s ease;\n//         }\n//         .listening-btn.listening {\n//           background-color: #00f;\n//         }\n//       `}</style>\n//     </div>\n//   );\n// };\n//\n// export default Assistant;\n\n\n///////////////////////////////////////////////////\n"],"mappings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},"metadata":{},"sourceType":"module"}