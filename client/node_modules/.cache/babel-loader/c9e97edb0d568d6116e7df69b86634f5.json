{"ast":null,"code":"var _jsxFileName = \"D:\\\\PROJECTS\\\\ScanVue\\\\client\\\\src\\\\components\\\\assistant.jsx\",\n  _s = $RefreshSig$();\n// import React from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { useHistory } from \"react-router-dom\";\n//\n// import { useSpeechSynthesis } from \"react-speech-kit\";\n//\n// const Assistant = () => {\n//   const history = useHistory();\n//   //   SpeechRecognition.startListening({ continuous: true });\n//   const { speak } = useSpeechSynthesis();\n//   const commands = [\n//     {\n//       command: \"Go to *\",\n//       callback: (link) => {\n//         const x = `Redirect to: ${link}`;\n//         console.log(x);\n//         if (link === \"object detection\") {\n//           speak({ text: x });\n//           history.push(`/object-detection`);\n//         }else if (link === \"face recognition\") {\n//           speak({ text: x });\n//           history.push(`/face-recognition`);\n//         }else if (link === \"image to text\") {\n//           speak({ text: x });\n//           history.push(`/image-to-text`);\n//         } else if (link === \"text to speech\") {\n//           speak({ text: x });\n//           history.push(`/text-to-speech`);\n//         } else if (link === \"speech to text\") {\n//           speak({ text: x });\n//           history.push(`/speech-to-text`);\n//         } else if (link === \"home\") {\n//           speak({ text: x });\n//           history.push(`/`);\n//         } else {\n//           speak({ text: \"I don't get it, Please try again!\" });\n//         }\n//       },\n//     },\n//     {\n//       command: \"Hey Jarvis\",\n//       callback: () => {\n//         speak({ text: \"Hi Sir\" });\n//\n//         console.log(\"hii\");\n//       },\n//       //   matchInterim: true,\n//     },\n//     // {\n//     //   command: \"*\",\n//     //   callback: () => {\n//     //     speak({ text: \"Please repeat\" });\n//\n//     //     console.log(\"repeat\");\n//     //   },\n//     // },\n//   ];\n//   const { transcript: t1 } = useSpeechRecognition({ commands });\n//\n//   return (\n//     <React.Fragment>\n//       <div\n//         className=\"row m-2 p-4\"\n//         style={{ background: \"#f5f5f5\", textAlign: \"center\" }}\n//       >\n//         <h1\n//           style={{\n//             fontFamily: \"Georgia, Times, serif\",\n//             fontSize: \"45px\",\n//             fontWeight: \"bolder\",\n//           }}\n//         >\n//           Assistant\n//         </h1>\n//       </div>\n//       <div style={{ border: \"10px solid gray\", padding: \"10px\" }}>\n// {/*         <div>Say \"Hey Jarvis\"</div> */}\n//         <h3>Say \"Hey Jarvis\"</h3>\n//         <p>{t1 ? t1 : \"Start listening for transcript\"}</p>\n//         <button onClick={SpeechRecognition.startListening}>\n//           Start listening\n//         </button>\n//         &nbsp;\n//         <button onClick={SpeechRecognition.stopListening}>\n//           Stop listening\n//         </button>\n//       </div>\n//     </React.Fragment>\n//   );\n// };\n//\n// export default Assistant;\n\n//////////////////////////////\n\n// import React, { useState } from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { useHistory } from \"react-router-dom\";\n//\n// import { useSpeechSynthesis } from \"react-speech-kit\";\n//\n// const Assistant = () => {\n//   const history = useHistory();\n//   const { speak } = useSpeechSynthesis();\n//   const [isListening, setIsListening] = useState(false);\n//\n//   const startListening = () => {\n//     setIsListening(true);\n//     SpeechRecognition.startListening({ continuous: true });\n//   };\n//\n//   const stopListening = () => {\n//     setIsListening(false);\n//     SpeechRecognition.stopListening();\n//   };\n//\n//   const commands = [\n//     {\n//       command: \"Go to *\",\n//       callback: (link) => {\n//         const x = `Redirect to: ${link}`;\n//         console.log(x);\n//         if (link === \"object detection\") {\n//           speak({ text: x });\n//           history.push(`/object-detection`);\n//         } else if (link === \"face recognition\") {\n//           speak({ text: x });\n//           history.push(`/face-recognition`);\n//         } else if (link === \"image to text\") {\n//           speak({ text: x });\n//           history.push(`/image-to-text`);\n//         } else if (link === \"text to speech\") {\n//           speak({ text: x });\n//           history.push(`/text-to-speech`);\n//         } else if (link === \"speech to text\") {\n//           speak({ text: x });\n//           history.push(`/speech-to-text`);\n//         } else if (link === \"home\") {\n//           speak({ text: x });\n//           history.push(`/`);\n//         } else {\n//           speak({ text: \"I don't get it, Please try again!\" });\n//         }\n//       },\n//     },\n//     {\n//       command: \"Hey Jarvis\",\n//       callback: () => {\n//         speak({ text: \"Hi Sir\" });\n//         console.log(\"hii\");\n//       },\n//     },\n//   ];\n//   const { transcript: t1 } = useSpeechRecognition({ commands });\n//\n//   return (\n//     <div className=\"phone-container\">\n//       <div className=\"phone\">\n//         <div className=\"phone-speaker\"></div>\n//         <div className=\"phone-screen\">\n//           <div className=\"assistant-container\">\n//             <div className=\"assistant-content\">\n//               <div className=\"assistant-title\">\n//                 <h1>Assistant</h1>\n//               </div>\n//               <div className=\"assistant-body\">\n//                 <h3>Say \"Hey Jarvis\"</h3>\n//                 <p>{t1 ? t1 : \"Start listening for transcript\"}</p>\n//                 <button\n//                   onClick={isListening ? stopListening : startListening}\n//                   className={`listening-btn ${isListening ? \"listening\" : \"\"}`}\n//                 >\n//                   {isListening ? \"Listening\" : \"Start Listening\"}\n//                 </button>\n//               </div>\n//             </div>\n//           </div>\n//         </div>\n//         <div className=\"phone-btns\">\n//           <div className=\"phone-btn phone-btn-red\"></div>\n//           <div className=\"phone-btn phone-btn-green\"></div>\n//           <div className=\"phone-btn phone-btn-blue\"></div>\n//         </div>\n//       </div>\n//       <style jsx>{`\n//         .phone-container {\n//           display: flex;\n//           justify-content: center;\n//           align-items: center;\n//           height: 100vh;\n//           background: linear-gradient(135deg, #2d75ff, #a8bfff);\n//         }\n//         .phone {\n//           position: relative;\n//           width: 300px;\n//           height: 600px;\n//           background: #000;\n//           border-radius: 20px;\n//           overflow: hidden;\n//           box-shadow: 0 0 20px rgba(0, 0, 0, 0.5);\n//         }\n//         .phone-speaker {\n//           position: absolute;\n//           top: 20px;\n//           left: 50%;\n//           transform: translateX(-50%);\n//           width: 50px;\n//           height: 5px;\n//           background: #666;\n//           border-radius: 50px;\n//         }\n//         .phone-screen {\n//           position: relative;\n//           width: 100%;\n//           height: 100%; /* Adjusted height */\n//           background: #fff;\n//           overflow-y: auto;\n//           padding: 20px;\n//         }\n//         .assistant-container {\n//           display: flex;\n//           justify-content: center;\n//           align-items: center;\n//           height: 100%;\n//         }\n//         .assistant-content {\n//           text-align: center;\n//         }\n//         .assistant-title {\n//           font-family: Georgia, Times, serif;\n//           font-size: 32px;\n//           font-weight: bolder;\n//           margin-bottom: 20px;\n//         }\n//         .assistant-body {\n//           margin-top: 20px;\n//         }\n//         .listening-btn {\n//           background-color: #f00;\n//           color: #fff;\n//           border: none;\n//           border-radius: 5px;\n//           padding: 10px;\n//           cursor: pointer;\n//           transition: background-color 0.3s ease;\n//         }\n//         .listening-btn.listening {\n//           background-color: #00f;\n//         }\n//         .phone-btns {\n//           position: absolute;\n//           bottom: 10px;\n//           left: 50%;\n//           transform: translateX(-50%);\n//           display: flex;\n//         }\n//         .phone-btn {\n//           width: 20px;\n//           height: 20px;\n//           border-radius: 50%;\n//           margin: 0 5px;\n//         }\n//         .phone-btn-red {\n//           background: #f00;\n//         }\n//         .phone-btn-green {\n//           background: #0f0;\n//         }\n//         .phone-btn-blue {\n//           background: #00f;\n//         }\n//       `}</style>\n//     </div>\n//   );\n// };\n//\n// export default Assistant;\n\n////////////////////////////////////// final working code\n\n// import React, { useState } from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { useHistory } from \"react-router-dom\";\n// import { useSpeechSynthesis } from \"react-speech-kit\";\n//\n// const Assistant = () => {\n//   const history = useHistory();\n//   const { speak } = useSpeechSynthesis();\n//   const [isListening, setIsListening] = useState(false);\n//\n//   const startListening = () => {\n//     setIsListening(true);\n//     SpeechRecognition.startListening({ continuous: true });\n//   };\n//\n//   const stopListening = () => {\n//     setIsListening(false);\n//     SpeechRecognition.stopListening();\n//   };\n//\n//   const commands = [\n//     {\n//       command: \"Go to *\",\n//       callback: (link) => {\n//         const x = `Redirect to: ${link}`;\n//         console.log(x);\n//         if (link === \"object detection\") {\n//           speak({ text: x });\n//           history.push(`/object-detection`);\n//         } else if (link === \"face recognition\") {\n//           speak({ text: x });\n//           history.push(`/face-recognition`);\n//         } else if (link === \"image to text\") {\n//           speak({ text: x });\n//           history.push(`/image-to-text`);\n//         } else if (link === \"text to speech\") {\n//           speak({ text: x });\n//           history.push(`/text-to-speech`);\n//         } else if (link === \"speech to text\") {\n//           speak({ text: x });\n//           history.push(`/speech-to-text`);\n//         } else if (link === \"home\") {\n//           speak({ text: x });\n//           history.push(`/`);\n//         } else {\n//           speak({ text: \"I don't get it, Please try again!\" });\n//         }\n//       },\n//     },\n//     {\n//       command: \"Jarvis\",\n//       callback: () => {\n//         speak({ text: \"Hi Sir\" });\n//         console.log(\"hii\");\n//       },\n//     },\n//   ];\n//   const { transcript: t1 } = useSpeechRecognition({ commands });\n//\n//   return (\n//     <div className=\"phone-container\">\n//       <div className=\"phone\">\n//         <div className=\"phone-screen\">\n//           <div className=\"assistant-container\">\n//             <div className=\"assistant-content\">\n//               <div className=\"assistant-title\">\n//                 <h1>Assistant</h1>\n//               </div>\n//               <div className=\"assistant-body\">\n//                 <h3>Say \"Jarvis\"</h3>\n//                 <p>{t1 ? t1 : \"Start listening for transcript\"}</p>\n//                 <button\n//                   onClick={isListening ? stopListening : startListening}\n//                   className={`listening-btn ${isListening ? \"listening\" : \"\"}`}\n//                 >\n//                   {isListening ? \"Listening\" : \"Start Listening\"}\n//                 </button>\n//               </div>\n//             </div>\n//           </div>\n//         </div>\n//       </div>\n//       <style jsx>{`\n//         .phone-container {\n//           display: flex;\n//           justify-content: center;\n//           align-items: center;\n//           height: 100vh; /* Adjust the height to match FaceRecognition */\n//           background: linear-gradient(135deg, #2d75ff, #a8bfff);\n//           overflow: hidden;\n//         }\n//         .phone {\n//           width: 85%; /* Adjust the width to match FaceRecognition */\n//           height: 95%; /* Adjust the height to match FaceRecognition */\n//           max-width: 750px;\n//           max-height: 800px;\n//           background: #333;\n//           border-radius: 20px;\n//           overflow: hidden;\n//           box-shadow: 0 0 20px rgba(0, 0, 0, 0.5);\n//         }\n//         .phone-screen {\n//           height: 100%;\n//           overflow-y: auto;\n//           padding: 20px;\n//           display: flex;\n//           flex-direction: column;\n//           justify-content: center;\n//           align-items: center;\n//           background: #fff;\n//         }\n//         .assistant-container {\n//           width: 100%;\n//           max-width: 400px;\n//         }\n//         .assistant-content {\n//           text-align: center;\n//         }\n//         .assistant-title {\n//           font-size: 28px;\n//           margin-bottom: 20px;\n//           text-shadow: 1px 1px 2px #000;\n//         }\n//         .assistant-body {\n//           margin-top: 20px;\n//         }\n//         .listening-btn {\n//           background-color: #f00;\n//           color: #fff;\n//           border: none;\n//           border-radius: 5px;\n//           padding: 10px;\n//           cursor: pointer;\n//           transition: background-color 0.3s ease;\n//         }\n//         .listening-btn.listening {\n//           background-color: #00f;\n//         }\n//       `}</style>\n//     </div>\n//   );\n// };\n//\n// export default Assistant;\n\n///////////////////////////////////////////////////\n\nimport React, { useState, useEffect } from \"react\";\nimport SpeechRecognition, { useSpeechRecognition } from \"react-speech-recognition\";\nimport { useHistory } from \"react-router-dom\";\nimport { useSpeechSynthesis } from \"react-speech-kit\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst Assistant = () => {\n  _s();\n  const history = useHistory();\n  const {\n    speak\n  } = useSpeechSynthesis();\n  const [isListening, setIsListening] = useState(false);\n  const {\n    transcript: t1,\n    resetTranscript\n  } = useSpeechRecognition();\n  useEffect(() => {\n    // Stop listening when component unmounts or navigates away\n    return () => {\n      SpeechRecognition.abortListening();\n    };\n  }, []);\n  const startListening = () => {\n    setIsListening(true);\n    SpeechRecognition.startListening({\n      continuous: true\n    });\n  };\n  const stopListening = () => {\n    setIsListening(false);\n    SpeechRecognition.stopListening();\n  };\n  const handleCommand = command => {\n    const x = `Redirect to: ${command}`;\n    console.log(x);\n    speak({\n      text: x\n    });\n    switch (command) {\n      case \"object detection\":\n        history.push(`/object-detection`);\n        break;\n      case \"face recognition\":\n        history.push(`/face-recognition`);\n        break;\n      case \"image to text\":\n        history.push(`/image-to-text`);\n        break;\n      case \"text to speech\":\n        history.push(`/text-to-speech`);\n        break;\n      case \"speech to text\":\n        history.push(`/speech-to-text`);\n        break;\n      case \"home\":\n        history.push(`/`);\n        break;\n      default:\n        speak({\n          text: \"I don't get it, Please try again!\"\n        });\n    }\n    resetTranscript(); // Reset transcript after executing command\n    stopListening(); // Stop listening after command is executed\n  };\n  const handleListeningClick = () => {\n    if (isListening) {\n      stopListening();\n    } else {\n      startListening();\n    }\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"phone-container\",\n    children: [/*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"phone\",\n      children: /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"phone-screen\",\n        children: /*#__PURE__*/_jsxDEV(\"div\", {\n          className: \"assistant-container\",\n          children: /*#__PURE__*/_jsxDEV(\"div\", {\n            className: \"assistant-content\",\n            children: [/*#__PURE__*/_jsxDEV(\"div\", {\n              className: \"assistant-title\",\n              children: /*#__PURE__*/_jsxDEV(\"h1\", {\n                children: \"Assistant\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 525,\n                columnNumber: 17\n              }, this)\n            }, void 0, false, {\n              fileName: _jsxFileName,\n              lineNumber: 524,\n              columnNumber: 15\n            }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n              className: \"assistant-body\",\n              children: [/*#__PURE__*/_jsxDEV(\"h3\", {\n                children: \"Say \\\"Jarvis\\\"\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 528,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n                children: t1 ? t1 : \"Start listening for transcript\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 529,\n                columnNumber: 17\n              }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n                onClick: handleListeningClick,\n                className: `listening-btn ${isListening ? \"listening\" : \"\"}`,\n                children: isListening ? \"Listening\" : \"Start Listening\"\n              }, void 0, false, {\n                fileName: _jsxFileName,\n                lineNumber: 530,\n                columnNumber: 17\n              }, this)]\n            }, void 0, true, {\n              fileName: _jsxFileName,\n              lineNumber: 527,\n              columnNumber: 15\n            }, this)]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 523,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 522,\n          columnNumber: 11\n        }, this)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 521,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 520,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"style\", {\n      jsx: true,\n      children: `\n        /* Your existing styling */\n      `\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 541,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 519,\n    columnNumber: 5\n  }, this);\n};\n_s(Assistant, \"jo3XTALwbbGGOH02YxPpY57xuUU=\", false, function () {\n  return [useHistory, useSpeechSynthesis, useSpeechRecognition];\n});\n_c = Assistant;\nexport default Assistant;\nvar _c;\n$RefreshReg$(_c, \"Assistant\");","map":{"version":3,"names":["React","useState","useEffect","SpeechRecognition","useSpeechRecognition","useHistory","useSpeechSynthesis","jsxDEV","_jsxDEV","Assistant","_s","history","speak","isListening","setIsListening","transcript","t1","resetTranscript","abortListening","startListening","continuous","stopListening","handleCommand","command","x","console","log","text","push","handleListeningClick","className","children","fileName","_jsxFileName","lineNumber","columnNumber","onClick","jsx","_c","$RefreshReg$"],"sources":["D:/PROJECTS/ScanVue/client/src/components/assistant.jsx"],"sourcesContent":["// import React from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { useHistory } from \"react-router-dom\";\n//\n// import { useSpeechSynthesis } from \"react-speech-kit\";\n//\n// const Assistant = () => {\n//   const history = useHistory();\n//   //   SpeechRecognition.startListening({ continuous: true });\n//   const { speak } = useSpeechSynthesis();\n//   const commands = [\n//     {\n//       command: \"Go to *\",\n//       callback: (link) => {\n//         const x = `Redirect to: ${link}`;\n//         console.log(x);\n//         if (link === \"object detection\") {\n//           speak({ text: x });\n//           history.push(`/object-detection`);\n//         }else if (link === \"face recognition\") {\n//           speak({ text: x });\n//           history.push(`/face-recognition`);\n//         }else if (link === \"image to text\") {\n//           speak({ text: x });\n//           history.push(`/image-to-text`);\n//         } else if (link === \"text to speech\") {\n//           speak({ text: x });\n//           history.push(`/text-to-speech`);\n//         } else if (link === \"speech to text\") {\n//           speak({ text: x });\n//           history.push(`/speech-to-text`);\n//         } else if (link === \"home\") {\n//           speak({ text: x });\n//           history.push(`/`);\n//         } else {\n//           speak({ text: \"I don't get it, Please try again!\" });\n//         }\n//       },\n//     },\n//     {\n//       command: \"Hey Jarvis\",\n//       callback: () => {\n//         speak({ text: \"Hi Sir\" });\n//\n//         console.log(\"hii\");\n//       },\n//       //   matchInterim: true,\n//     },\n//     // {\n//     //   command: \"*\",\n//     //   callback: () => {\n//     //     speak({ text: \"Please repeat\" });\n//\n//     //     console.log(\"repeat\");\n//     //   },\n//     // },\n//   ];\n//   const { transcript: t1 } = useSpeechRecognition({ commands });\n//\n//   return (\n//     <React.Fragment>\n//       <div\n//         className=\"row m-2 p-4\"\n//         style={{ background: \"#f5f5f5\", textAlign: \"center\" }}\n//       >\n//         <h1\n//           style={{\n//             fontFamily: \"Georgia, Times, serif\",\n//             fontSize: \"45px\",\n//             fontWeight: \"bolder\",\n//           }}\n//         >\n//           Assistant\n//         </h1>\n//       </div>\n//       <div style={{ border: \"10px solid gray\", padding: \"10px\" }}>\n// {/*         <div>Say \"Hey Jarvis\"</div> */}\n//         <h3>Say \"Hey Jarvis\"</h3>\n//         <p>{t1 ? t1 : \"Start listening for transcript\"}</p>\n//         <button onClick={SpeechRecognition.startListening}>\n//           Start listening\n//         </button>\n//         &nbsp;\n//         <button onClick={SpeechRecognition.stopListening}>\n//           Stop listening\n//         </button>\n//       </div>\n//     </React.Fragment>\n//   );\n// };\n//\n// export default Assistant;\n\n\n\n\n\n\n\n//////////////////////////////\n\n\n\n// import React, { useState } from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { useHistory } from \"react-router-dom\";\n//\n// import { useSpeechSynthesis } from \"react-speech-kit\";\n//\n// const Assistant = () => {\n//   const history = useHistory();\n//   const { speak } = useSpeechSynthesis();\n//   const [isListening, setIsListening] = useState(false);\n//\n//   const startListening = () => {\n//     setIsListening(true);\n//     SpeechRecognition.startListening({ continuous: true });\n//   };\n//\n//   const stopListening = () => {\n//     setIsListening(false);\n//     SpeechRecognition.stopListening();\n//   };\n//\n//   const commands = [\n//     {\n//       command: \"Go to *\",\n//       callback: (link) => {\n//         const x = `Redirect to: ${link}`;\n//         console.log(x);\n//         if (link === \"object detection\") {\n//           speak({ text: x });\n//           history.push(`/object-detection`);\n//         } else if (link === \"face recognition\") {\n//           speak({ text: x });\n//           history.push(`/face-recognition`);\n//         } else if (link === \"image to text\") {\n//           speak({ text: x });\n//           history.push(`/image-to-text`);\n//         } else if (link === \"text to speech\") {\n//           speak({ text: x });\n//           history.push(`/text-to-speech`);\n//         } else if (link === \"speech to text\") {\n//           speak({ text: x });\n//           history.push(`/speech-to-text`);\n//         } else if (link === \"home\") {\n//           speak({ text: x });\n//           history.push(`/`);\n//         } else {\n//           speak({ text: \"I don't get it, Please try again!\" });\n//         }\n//       },\n//     },\n//     {\n//       command: \"Hey Jarvis\",\n//       callback: () => {\n//         speak({ text: \"Hi Sir\" });\n//         console.log(\"hii\");\n//       },\n//     },\n//   ];\n//   const { transcript: t1 } = useSpeechRecognition({ commands });\n//\n//   return (\n//     <div className=\"phone-container\">\n//       <div className=\"phone\">\n//         <div className=\"phone-speaker\"></div>\n//         <div className=\"phone-screen\">\n//           <div className=\"assistant-container\">\n//             <div className=\"assistant-content\">\n//               <div className=\"assistant-title\">\n//                 <h1>Assistant</h1>\n//               </div>\n//               <div className=\"assistant-body\">\n//                 <h3>Say \"Hey Jarvis\"</h3>\n//                 <p>{t1 ? t1 : \"Start listening for transcript\"}</p>\n//                 <button\n//                   onClick={isListening ? stopListening : startListening}\n//                   className={`listening-btn ${isListening ? \"listening\" : \"\"}`}\n//                 >\n//                   {isListening ? \"Listening\" : \"Start Listening\"}\n//                 </button>\n//               </div>\n//             </div>\n//           </div>\n//         </div>\n//         <div className=\"phone-btns\">\n//           <div className=\"phone-btn phone-btn-red\"></div>\n//           <div className=\"phone-btn phone-btn-green\"></div>\n//           <div className=\"phone-btn phone-btn-blue\"></div>\n//         </div>\n//       </div>\n//       <style jsx>{`\n//         .phone-container {\n//           display: flex;\n//           justify-content: center;\n//           align-items: center;\n//           height: 100vh;\n//           background: linear-gradient(135deg, #2d75ff, #a8bfff);\n//         }\n//         .phone {\n//           position: relative;\n//           width: 300px;\n//           height: 600px;\n//           background: #000;\n//           border-radius: 20px;\n//           overflow: hidden;\n//           box-shadow: 0 0 20px rgba(0, 0, 0, 0.5);\n//         }\n//         .phone-speaker {\n//           position: absolute;\n//           top: 20px;\n//           left: 50%;\n//           transform: translateX(-50%);\n//           width: 50px;\n//           height: 5px;\n//           background: #666;\n//           border-radius: 50px;\n//         }\n//         .phone-screen {\n//           position: relative;\n//           width: 100%;\n//           height: 100%; /* Adjusted height */\n//           background: #fff;\n//           overflow-y: auto;\n//           padding: 20px;\n//         }\n//         .assistant-container {\n//           display: flex;\n//           justify-content: center;\n//           align-items: center;\n//           height: 100%;\n//         }\n//         .assistant-content {\n//           text-align: center;\n//         }\n//         .assistant-title {\n//           font-family: Georgia, Times, serif;\n//           font-size: 32px;\n//           font-weight: bolder;\n//           margin-bottom: 20px;\n//         }\n//         .assistant-body {\n//           margin-top: 20px;\n//         }\n//         .listening-btn {\n//           background-color: #f00;\n//           color: #fff;\n//           border: none;\n//           border-radius: 5px;\n//           padding: 10px;\n//           cursor: pointer;\n//           transition: background-color 0.3s ease;\n//         }\n//         .listening-btn.listening {\n//           background-color: #00f;\n//         }\n//         .phone-btns {\n//           position: absolute;\n//           bottom: 10px;\n//           left: 50%;\n//           transform: translateX(-50%);\n//           display: flex;\n//         }\n//         .phone-btn {\n//           width: 20px;\n//           height: 20px;\n//           border-radius: 50%;\n//           margin: 0 5px;\n//         }\n//         .phone-btn-red {\n//           background: #f00;\n//         }\n//         .phone-btn-green {\n//           background: #0f0;\n//         }\n//         .phone-btn-blue {\n//           background: #00f;\n//         }\n//       `}</style>\n//     </div>\n//   );\n// };\n//\n// export default Assistant;\n\n\n\n////////////////////////////////////// final working code\n\n\n\n\n// import React, { useState } from \"react\";\n// import SpeechRecognition, {\n//   useSpeechRecognition,\n// } from \"react-speech-recognition\";\n// import { useHistory } from \"react-router-dom\";\n// import { useSpeechSynthesis } from \"react-speech-kit\";\n//\n// const Assistant = () => {\n//   const history = useHistory();\n//   const { speak } = useSpeechSynthesis();\n//   const [isListening, setIsListening] = useState(false);\n//\n//   const startListening = () => {\n//     setIsListening(true);\n//     SpeechRecognition.startListening({ continuous: true });\n//   };\n//\n//   const stopListening = () => {\n//     setIsListening(false);\n//     SpeechRecognition.stopListening();\n//   };\n//\n//   const commands = [\n//     {\n//       command: \"Go to *\",\n//       callback: (link) => {\n//         const x = `Redirect to: ${link}`;\n//         console.log(x);\n//         if (link === \"object detection\") {\n//           speak({ text: x });\n//           history.push(`/object-detection`);\n//         } else if (link === \"face recognition\") {\n//           speak({ text: x });\n//           history.push(`/face-recognition`);\n//         } else if (link === \"image to text\") {\n//           speak({ text: x });\n//           history.push(`/image-to-text`);\n//         } else if (link === \"text to speech\") {\n//           speak({ text: x });\n//           history.push(`/text-to-speech`);\n//         } else if (link === \"speech to text\") {\n//           speak({ text: x });\n//           history.push(`/speech-to-text`);\n//         } else if (link === \"home\") {\n//           speak({ text: x });\n//           history.push(`/`);\n//         } else {\n//           speak({ text: \"I don't get it, Please try again!\" });\n//         }\n//       },\n//     },\n//     {\n//       command: \"Jarvis\",\n//       callback: () => {\n//         speak({ text: \"Hi Sir\" });\n//         console.log(\"hii\");\n//       },\n//     },\n//   ];\n//   const { transcript: t1 } = useSpeechRecognition({ commands });\n//\n//   return (\n//     <div className=\"phone-container\">\n//       <div className=\"phone\">\n//         <div className=\"phone-screen\">\n//           <div className=\"assistant-container\">\n//             <div className=\"assistant-content\">\n//               <div className=\"assistant-title\">\n//                 <h1>Assistant</h1>\n//               </div>\n//               <div className=\"assistant-body\">\n//                 <h3>Say \"Jarvis\"</h3>\n//                 <p>{t1 ? t1 : \"Start listening for transcript\"}</p>\n//                 <button\n//                   onClick={isListening ? stopListening : startListening}\n//                   className={`listening-btn ${isListening ? \"listening\" : \"\"}`}\n//                 >\n//                   {isListening ? \"Listening\" : \"Start Listening\"}\n//                 </button>\n//               </div>\n//             </div>\n//           </div>\n//         </div>\n//       </div>\n//       <style jsx>{`\n//         .phone-container {\n//           display: flex;\n//           justify-content: center;\n//           align-items: center;\n//           height: 100vh; /* Adjust the height to match FaceRecognition */\n//           background: linear-gradient(135deg, #2d75ff, #a8bfff);\n//           overflow: hidden;\n//         }\n//         .phone {\n//           width: 85%; /* Adjust the width to match FaceRecognition */\n//           height: 95%; /* Adjust the height to match FaceRecognition */\n//           max-width: 750px;\n//           max-height: 800px;\n//           background: #333;\n//           border-radius: 20px;\n//           overflow: hidden;\n//           box-shadow: 0 0 20px rgba(0, 0, 0, 0.5);\n//         }\n//         .phone-screen {\n//           height: 100%;\n//           overflow-y: auto;\n//           padding: 20px;\n//           display: flex;\n//           flex-direction: column;\n//           justify-content: center;\n//           align-items: center;\n//           background: #fff;\n//         }\n//         .assistant-container {\n//           width: 100%;\n//           max-width: 400px;\n//         }\n//         .assistant-content {\n//           text-align: center;\n//         }\n//         .assistant-title {\n//           font-size: 28px;\n//           margin-bottom: 20px;\n//           text-shadow: 1px 1px 2px #000;\n//         }\n//         .assistant-body {\n//           margin-top: 20px;\n//         }\n//         .listening-btn {\n//           background-color: #f00;\n//           color: #fff;\n//           border: none;\n//           border-radius: 5px;\n//           padding: 10px;\n//           cursor: pointer;\n//           transition: background-color 0.3s ease;\n//         }\n//         .listening-btn.listening {\n//           background-color: #00f;\n//         }\n//       `}</style>\n//     </div>\n//   );\n// };\n//\n// export default Assistant;\n\n\n///////////////////////////////////////////////////\n\n\n\nimport React, { useState, useEffect } from \"react\";\nimport SpeechRecognition, {\n  useSpeechRecognition,\n} from \"react-speech-recognition\";\nimport { useHistory } from \"react-router-dom\";\nimport { useSpeechSynthesis } from \"react-speech-kit\";\n\nconst Assistant = () => {\n  const history = useHistory();\n  const { speak } = useSpeechSynthesis();\n  const [isListening, setIsListening] = useState(false);\n  const { transcript: t1, resetTranscript } = useSpeechRecognition();\n\n  useEffect(() => {\n    // Stop listening when component unmounts or navigates away\n    return () => {\n      SpeechRecognition.abortListening();\n    };\n  }, []);\n\n  const startListening = () => {\n    setIsListening(true);\n    SpeechRecognition.startListening({ continuous: true });\n  };\n\n  const stopListening = () => {\n    setIsListening(false);\n    SpeechRecognition.stopListening();\n  };\n\n  const handleCommand = (command) => {\n    const x = `Redirect to: ${command}`;\n    console.log(x);\n    speak({ text: x });\n    switch (command) {\n      case \"object detection\":\n        history.push(`/object-detection`);\n        break;\n      case \"face recognition\":\n        history.push(`/face-recognition`);\n        break;\n      case \"image to text\":\n        history.push(`/image-to-text`);\n        break;\n      case \"text to speech\":\n        history.push(`/text-to-speech`);\n        break;\n      case \"speech to text\":\n        history.push(`/speech-to-text`);\n        break;\n      case \"home\":\n        history.push(`/`);\n        break;\n      default:\n        speak({ text: \"I don't get it, Please try again!\" });\n    }\n    resetTranscript(); // Reset transcript after executing command\n    stopListening(); // Stop listening after command is executed\n  };\n\n  const handleListeningClick = () => {\n    if (isListening) {\n      stopListening();\n    } else {\n      startListening();\n    }\n  };\n\n  return (\n    <div className=\"phone-container\">\n      <div className=\"phone\">\n        <div className=\"phone-screen\">\n          <div className=\"assistant-container\">\n            <div className=\"assistant-content\">\n              <div className=\"assistant-title\">\n                <h1>Assistant</h1>\n              </div>\n              <div className=\"assistant-body\">\n                <h3>Say \"Jarvis\"</h3>\n                <p>{t1 ? t1 : \"Start listening for transcript\"}</p>\n                <button\n                  onClick={handleListeningClick}\n                  className={`listening-btn ${isListening ? \"listening\" : \"\"}`}\n                >\n                  {isListening ? \"Listening\" : \"Start Listening\"}\n                </button>\n              </div>\n            </div>\n          </div>\n        </div>\n      </div>\n      <style jsx>{`\n        /* Your existing styling */\n      `}</style>\n    </div>\n  );\n};\n\nexport default Assistant;\n\n"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAQA;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAIA;;AAKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAGA;;AAIA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,QAAQ,OAAO;AAClD,OAAOC,iBAAiB,IACtBC,oBAAoB,QACf,0BAA0B;AACjC,SAASC,UAAU,QAAQ,kBAAkB;AAC7C,SAASC,kBAAkB,QAAQ,kBAAkB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEtD,MAAMC,SAAS,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACtB,MAAMC,OAAO,GAAGN,UAAU,CAAC,CAAC;EAC5B,MAAM;IAAEO;EAAM,CAAC,GAAGN,kBAAkB,CAAC,CAAC;EACtC,MAAM,CAACO,WAAW,EAAEC,cAAc,CAAC,GAAGb,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM;IAAEc,UAAU,EAAEC,EAAE;IAAEC;EAAgB,CAAC,GAAGb,oBAAoB,CAAC,CAAC;EAElEF,SAAS,CAAC,MAAM;IACd;IACA,OAAO,MAAM;MACXC,iBAAiB,CAACe,cAAc,CAAC,CAAC;IACpC,CAAC;EACH,CAAC,EAAE,EAAE,CAAC;EAEN,MAAMC,cAAc,GAAGA,CAAA,KAAM;IAC3BL,cAAc,CAAC,IAAI,CAAC;IACpBX,iBAAiB,CAACgB,cAAc,CAAC;MAAEC,UAAU,EAAE;IAAK,CAAC,CAAC;EACxD,CAAC;EAED,MAAMC,aAAa,GAAGA,CAAA,KAAM;IAC1BP,cAAc,CAAC,KAAK,CAAC;IACrBX,iBAAiB,CAACkB,aAAa,CAAC,CAAC;EACnC,CAAC;EAED,MAAMC,aAAa,GAAIC,OAAO,IAAK;IACjC,MAAMC,CAAC,GAAI,gBAAeD,OAAQ,EAAC;IACnCE,OAAO,CAACC,GAAG,CAACF,CAAC,CAAC;IACdZ,KAAK,CAAC;MAAEe,IAAI,EAAEH;IAAE,CAAC,CAAC;IAClB,QAAQD,OAAO;MACb,KAAK,kBAAkB;QACrBZ,OAAO,CAACiB,IAAI,CAAE,mBAAkB,CAAC;QACjC;MACF,KAAK,kBAAkB;QACrBjB,OAAO,CAACiB,IAAI,CAAE,mBAAkB,CAAC;QACjC;MACF,KAAK,eAAe;QAClBjB,OAAO,CAACiB,IAAI,CAAE,gBAAe,CAAC;QAC9B;MACF,KAAK,gBAAgB;QACnBjB,OAAO,CAACiB,IAAI,CAAE,iBAAgB,CAAC;QAC/B;MACF,KAAK,gBAAgB;QACnBjB,OAAO,CAACiB,IAAI,CAAE,iBAAgB,CAAC;QAC/B;MACF,KAAK,MAAM;QACTjB,OAAO,CAACiB,IAAI,CAAE,GAAE,CAAC;QACjB;MACF;QACEhB,KAAK,CAAC;UAAEe,IAAI,EAAE;QAAoC,CAAC,CAAC;IACxD;IACAV,eAAe,CAAC,CAAC,CAAC,CAAC;IACnBI,aAAa,CAAC,CAAC,CAAC,CAAC;EACnB,CAAC;EAED,MAAMQ,oBAAoB,GAAGA,CAAA,KAAM;IACjC,IAAIhB,WAAW,EAAE;MACfQ,aAAa,CAAC,CAAC;IACjB,CAAC,MAAM;MACLF,cAAc,CAAC,CAAC;IAClB;EACF,CAAC;EAED,oBACEX,OAAA;IAAKsB,SAAS,EAAC,iBAAiB;IAAAC,QAAA,gBAC9BvB,OAAA;MAAKsB,SAAS,EAAC,OAAO;MAAAC,QAAA,eACpBvB,OAAA;QAAKsB,SAAS,EAAC,cAAc;QAAAC,QAAA,eAC3BvB,OAAA;UAAKsB,SAAS,EAAC,qBAAqB;UAAAC,QAAA,eAClCvB,OAAA;YAAKsB,SAAS,EAAC,mBAAmB;YAAAC,QAAA,gBAChCvB,OAAA;cAAKsB,SAAS,EAAC,iBAAiB;cAAAC,QAAA,eAC9BvB,OAAA;gBAAAuB,QAAA,EAAI;cAAS;gBAAAC,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI;YAAC;cAAAH,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OACf,CAAC,eACN3B,OAAA;cAAKsB,SAAS,EAAC,gBAAgB;cAAAC,QAAA,gBAC7BvB,OAAA;gBAAAuB,QAAA,EAAI;cAAY;gBAAAC,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,eACrB3B,OAAA;gBAAAuB,QAAA,EAAIf,EAAE,GAAGA,EAAE,GAAG;cAAgC;gBAAAgB,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OAAI,CAAC,eACnD3B,OAAA;gBACE4B,OAAO,EAAEP,oBAAqB;gBAC9BC,SAAS,EAAG,iBAAgBjB,WAAW,GAAG,WAAW,GAAG,EAAG,EAAE;gBAAAkB,QAAA,EAE5DlB,WAAW,GAAG,WAAW,GAAG;cAAiB;gBAAAmB,QAAA,EAAAC,YAAA;gBAAAC,UAAA;gBAAAC,YAAA;cAAA,OACxC,CAAC;YAAA;cAAAH,QAAA,EAAAC,YAAA;cAAAC,UAAA;cAAAC,YAAA;YAAA,OACN,CAAC;UAAA;YAAAH,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OACH;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACH;MAAC;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACH;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACH,CAAC,eACN3B,OAAA;MAAO6B,GAAG;MAAAN,QAAA,EAAG;AACnB;AACA;IAAO;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACP,CAAC;AAEV,CAAC;AAACzB,EAAA,CAzFID,SAAS;EAAA,QACGJ,UAAU,EACRC,kBAAkB,EAEQF,oBAAoB;AAAA;AAAAkC,EAAA,GAJ5D7B,SAAS;AA2Ff,eAAeA,SAAS;AAAC,IAAA6B,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module"}